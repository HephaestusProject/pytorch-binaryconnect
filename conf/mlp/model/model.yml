model:
  type: BinaryLinear

  params:
    width: 28
    height: 28
    channels: 1
    in_feature: &in_feature 784
    classes: &out_feature 10
    mode: &mode stochastic # stochastic or deterministic

    feature_layers:
      linear:
        - in_feature: *in_feature
          out_feature: 1024
          bias: true
          batch_norm: true
          activation:
            type: ReLU
            args: {}
          mode: *mode

        - in_feature: 1024
          out_feature: 1024
          bias: true
          batch_norm: true
          activation:
            type: ReLU
            args: {}
          mode: *mode
        # TODO. `in_feature` -> `in_features`
        # TODO. `out_feature` -> `out_features`
        - in_feature: 1024
          out_feature: 1024
          bias: true
          batch_norm: true
          activation: null
          mode: *mode

    output_layer:
      type: Linear
      args:
        in_features: 1024
        out_features: *out_feature
        bias: true
